{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbc08f50-468f-4282-86d8-daa83faca073",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a42602-e834-4850-99e1-5204ab1c38de",
   "metadata": {},
   "source": [
    "To compute the ML performance of the proposed method in near real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b76ffd-67e4-4633-937c-d8a14f6d0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import CAN_objects.aid_message\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "actt_path = os.path.join(os.path.join(os.path.expanduser(\"~\"), \"Projects\", \"CAN\", \"actt\"))\n",
    "os.chdir(actt_path)\n",
    "sys.path.insert(0, \"src\") # add src folder to path so that files from this folder can be imported\n",
    "\n",
    "from generalFunctions import unpickle\n",
    "import subprocess\n",
    "\n",
    "import importlib\n",
    "importlib.reload(CAN_objects.aid_message)\n",
    "from init_cancapture_from_canlog import init_cancap\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from CAN_objects.capture import MappedCapture, MatchedCapture\n",
    "import math\n",
    "from scipy.cluster.hierarchy import single, complete, average, ward, dendrogram, linkage, fcluster\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "from clusim.clustering import Clustering, remap2match\n",
    "import clusim.sim as sim\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.stats import shapiro, mannwhitneyu, ttest_ind, spearmanr\n",
    "from sklearn.preprocessing import normalize, scale, MinMaxScaler, StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5139d795-5d61-4d58-b89a-60be905a32cf",
   "metadata": {},
   "source": [
    "## Enable the Use of Functions From the Detect Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e912d5-a9c0-492d-b7e5-eacf63fa46be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloud/Projects/CAN/actt\n"
     ]
    }
   ],
   "source": [
    "# sys.path.insert(0, \"/home/cades/Projects/CAN/detect/\") # add detect folder to path so that files from this folder can be imported\n",
    "sys.path.insert(0, \"/home/cloud/Projects/CAN/detect/\") # add detect folder to path so that files from this folder can be imported\n",
    "import signal_based_preprocess_functions\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14463891-cf80-4218-ba7d-8f2207cd2c28",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d1e7d8-fda7-4638-9510-f53dc3f381eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_capture_to_time_series(cap, ground_truth_dbc_path):\n",
    "    \n",
    "    signal_multivar_ts, timepts, aid_signal_tups = signal_based_preprocess_functions.capture_to_mv_signal_timeseries(cap, ground_truth_dbc_path)\n",
    "\n",
    "    return signal_multivar_ts, timepts, aid_signal_tups\n",
    "\n",
    "\n",
    "def from_captures_to_time_series(cap_1, cap_2, ground_truth_dbc_path):\n",
    "        \n",
    "    signal_multivar_ts_1, timepts_1, aid_signal_tups_1 = signal_based_preprocess_functions.capture_to_mv_signal_timeseries(cap_1, ground_truth_dbc_path)\n",
    "    signal_multivar_ts_2, timepts_2, aid_signal_tups_2 = signal_based_preprocess_functions.capture_to_mv_signal_timeseries(cap_2, ground_truth_dbc_path)\n",
    "\n",
    "    return signal_multivar_ts_1, timepts_1, aid_signal_tups_1, signal_multivar_ts_2, timepts_2, aid_signal_tups_2\n",
    "\n",
    "\n",
    "def remove_constant_signals(signal_multivar_ts):\n",
    "    return signal_multivar_ts[:, ~np.all(signal_multivar_ts[1:] == signal_multivar_ts[:-1], axis=0)]\n",
    "\n",
    "\n",
    "def partition_time_series(signal_multivar_ts, window_length, offset):\n",
    "    \n",
    "    n = signal_multivar_ts.shape[0]\n",
    "    i = 0\n",
    "    partition = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition.append(signal_multivar_ts[i: i + window_length,:])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition.append(signal_multivar_ts[i:n,:])\n",
    "        \n",
    "    return partition\n",
    "    \n",
    "    \n",
    "def process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window_length, offset):\n",
    "    \n",
    "    # First dataframe\n",
    "    # Convert matrix of time series into a dataframe\n",
    "    df = pd.DataFrame({f\"{tup[0]}_{tup[1]}\": signal_multivar_ts[:,index] for index, tup in enumerate(aid_signal_tups)})\n",
    "    # display(df)\n",
    "\n",
    "    # Remove columns with constant values\n",
    "    df = df.loc[:, (df != df.iloc[0]).any()] \n",
    "    # display(df)\n",
    "    \n",
    "    # Stadarization\n",
    "    df_standardized = (df-df.mean())/df.std()\n",
    "    # display(df_standardized)\n",
    "    \n",
    "    # Partition of data frames\n",
    "    n = df_standardized.shape[0]\n",
    "    i = 0\n",
    "    partition = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition.append(df_standardized.iloc[i:i + window_length, :])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition.append(df_standardized.iloc[i:n, :])\n",
    "        \n",
    "    return partition\n",
    "\n",
    "\n",
    "def process_multiple_multivariate_signals(signal_multivar_ts_1, aid_signal_tups_1, signal_multivar_ts_2, aid_signal_tups_2, window_length, offset):\n",
    "    \n",
    "    # First dataframe\n",
    "    # Convert matrix of time series into a dataframe\n",
    "    df_1 = pd.DataFrame({f\"{tup[0]}_{tup[1]}\": signal_multivar_ts_1[:,index] for index, tup in enumerate(aid_signal_tups_1)})\n",
    "    # display(df)\n",
    "    print(df_1.shape)\n",
    "\n",
    "    # Remove columns with constant values\n",
    "    df_1 = df_1.loc[:, (df_1 != df_1.iloc[0]).any()] \n",
    "    # display(df)\n",
    "    \n",
    "    # Stadarization\n",
    "    df_1_standardized = (df_1-df_1.mean())/df_1.std()\n",
    "    # display(df_2_standardized)\n",
    "    \n",
    "    # Partition of data frames\n",
    "    n = df_1_standardized.shape[0]\n",
    "    i = 0\n",
    "    partition_1 = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition_1.append(df_1_standardized.iloc[i:i + window_length, :])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition_1.append(df_1_standardized.iloc[i:n, :])\n",
    "        \n",
    "        \n",
    "    # Second dataframe\n",
    "    # Convert matrix of time series into a dataframe\n",
    "    df_2 = pd.DataFrame({f\"{tup[0]}_{tup[1]}\": signal_multivar_ts_2[:,index] for index, tup in enumerate(aid_signal_tups_2)})\n",
    "    # display(df)\n",
    "    print(df_2.shape)\n",
    "\n",
    "    # Remove columns with constant values\n",
    "    df_2 = df_2.loc[:, (df_2 != df_2.iloc[0]).any()] \n",
    "    # display(df)\n",
    "    \n",
    "    # Stadarization\n",
    "    df_2_standardized = (df_2-df_2.mean())/df_2.std()\n",
    "    # display(df_2_standardized)\n",
    "    \n",
    "    # Partition of data frames\n",
    "    n = df_2_standardized.shape[0]\n",
    "    i = 0\n",
    "    partition_2 = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition_2.append(df_2_standardized.iloc[i:i + window_length, :])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition_2.append(df_2_standardized.iloc[i:n, :])\n",
    "        \n",
    "    return partition_1, partition_2\n",
    "\n",
    "\n",
    "def upper(df):\n",
    "    '''Returns the upper triangle of a correlation matrix.\n",
    "    You can use scipy.spatial.distance.squareform to recreate matrix from upper triangle.\n",
    "    Args:\n",
    "      df: pandas or numpy correlation matrix\n",
    "    Returns:\n",
    "      list of values from upper triangle\n",
    "    '''\n",
    "    try:\n",
    "        assert(type(df) == np.ndarray)\n",
    "    except:\n",
    "        if type(df) == pd.DataFrame:\n",
    "            df = df.values\n",
    "        else:\n",
    "            raise TypeError('Must be np.ndarray or pd.DataFrame')\n",
    "    mask = np.triu_indices(df.shape[0], k=1)\n",
    "    \n",
    "    return df[mask]\n",
    "\n",
    "\n",
    "\n",
    "def randomized_test_permutations(m1, m2):\n",
    "    \"\"\"Nonparametric permutation testing Monte Carlo\"\"\"\n",
    "    np.random.seed(0)\n",
    "    rhos = []\n",
    "    n_iter = 100\n",
    "    true_rho, _ = spearmanr(upper(m1), upper(m2))\n",
    "    # matrix permutation, shuffle the groups\n",
    "    m_ids = list(m1.columns)\n",
    "    m2_v = upper(m2)\n",
    "    for iter in range(n_iter):\n",
    "        np.random.shuffle(m_ids) # shuffle list \n",
    "        r, _ = spearmanr(upper(m1.loc[m_ids, m_ids]), m2_v)  \n",
    "        rhos.append(r)\n",
    "    perm_p = ((np.sum(np.abs(true_rho) <= np.abs(rhos)))+1)/(n_iter+1) # two-tailed test\n",
    "\n",
    "    return perm_p\n",
    "\n",
    "\n",
    "def compute_correlation_matrices(partition):\n",
    "    \n",
    "    corr_matrices = []\n",
    "\n",
    "    for df in partition:\n",
    "\n",
    "        # Remove columns with constant values\n",
    "        df = df.loc[:, (df != df.iloc[0]).any()] \n",
    "\n",
    "        # Compute correlation matrix\n",
    "        corr_matrices.append(df.corr(method=\"pearson\"))\n",
    "        \n",
    "    return corr_matrices\n",
    "\n",
    "\n",
    "def compute_similarity_from_correlation_matrices(corr_matrices):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(corr_matrices)-1):\n",
    "\n",
    "        # print(\"raw: \", corr_matrices[i].shape, corr_matrices[i+1].shape)\n",
    "\n",
    "        signal_names_1 = corr_matrices[i].columns.values\n",
    "        signal_names_2 = corr_matrices[i+1].columns.values\n",
    "        signal_names_intersection = list(set(signal_names_1).intersection(set(signal_names_2)))\n",
    "\n",
    "        df_1 = corr_matrices[i].loc[signal_names_intersection, signal_names_intersection] \n",
    "        df_2 = corr_matrices[i+1].loc[signal_names_intersection, signal_names_intersection]\n",
    "  \n",
    "        # print(\"pro: \", df_1.shape, df_2.shape, \"\\n\")\n",
    "\n",
    "        similarities.append((df_1.shape[0], spearmanr(upper(df_1), upper(df_2))[0], spearmanr(upper(df_1), upper(df_2))[1]))\n",
    "        \n",
    "    return similarities\n",
    "\n",
    "\n",
    "def compute_similarity_from_multiple_correlation_matrices(corr_matrices_1, corr_matrices_2):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    if len(corr_matrices_1) <= len(corr_matrices_2):\n",
    "        corr_matrices_reference = corr_matrices_1\n",
    "    else:\n",
    "        corr_matrices_reference = corr_matrices_2\n",
    "        \n",
    "    print(len(corr_matrices_reference))\n",
    "            \n",
    "    for i in range(len(corr_matrices_reference)):\n",
    "\n",
    "        # print(\"raw: \", corr_matrices[i].shape, corr_matrices[i+1].shape)\n",
    "\n",
    "        signal_names_1 = corr_matrices_1[i].columns.values\n",
    "        signal_names_2 = corr_matrices_2[i].columns.values\n",
    "        signal_names_intersection = list(set(signal_names_1).intersection(set(signal_names_2)))\n",
    "\n",
    "        df_1 = corr_matrices_1[i].loc[signal_names_intersection, signal_names_intersection] \n",
    "        df_2 = corr_matrices_2[i].loc[signal_names_intersection, signal_names_intersection]\n",
    "  \n",
    "        # print(\"pro: \", df_1.shape, df_2.shape, \"\\n\")\n",
    "\n",
    "        # similarities.append((df_1.shape[0], spearmanr(upper(df_1), upper(df_2))[0], spearmanr(upper(df_1), upper(df_2))[1]))\n",
    "        \n",
    "        correlation = spearmanr(upper(df_1), upper(df_2))[0]\n",
    "        p_value = spearmanr(upper(df_1), upper(df_2))[1]\n",
    "        \n",
    "        if p_value > 0.05:\n",
    "            similarities.append((i, correlation, p_value))\n",
    "        else:\n",
    "            similarities.append(i)\n",
    "            \n",
    "        \n",
    "    return similarities\n",
    "\n",
    "\n",
    "def create_time_intervals(total_length, window, offset):\n",
    "    \n",
    "    # Partition of data frames\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    \n",
    "    while (i + window) < total_length:\n",
    "        intervals.append((i, i + window))\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != total_length:\n",
    "        intervals.append((i , total_length))\n",
    "        \n",
    "    return intervals\n",
    "\n",
    "\n",
    "    # # Partition of data frames\n",
    "    # n = df_standardized.shape[0]\n",
    "    # i = 0\n",
    "    # partition = []\n",
    "    \n",
    "    # while (i + window_length) < n:\n",
    "    #     partition.append(df_standardized.iloc[i:i + window_length, :])\n",
    "    #     i = i + offset\n",
    "        \n",
    "    # if i != n:\n",
    "    #     partition.append(df_standardized.iloc[i:n, :])\n",
    "        \n",
    "    # return partition\n",
    "    \n",
    "\n",
    "    # intervals = []\n",
    "    # # offset = 0.1*offset\n",
    "    \n",
    "    # for i in np.arange(0, total_length - window + 1, offset, dtype=float):\n",
    "    #     intervals.append((i, i + window))\n",
    "\n",
    "    # if i + window < total_length:\n",
    "    #     intervals.append((i + offset, total_length))\n",
    "\n",
    "    # return intervals    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "222ac358-1bc4-4761-a750-f79bc8ffd691",
   "metadata": {},
   "source": [
    "## File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0839c292-b451-4341-8521-2361dede59a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['road_ambient_dyno_drive_basic_short_020822_030640', 'road_ambient_dyno_idle_radio_infotainment_030410_144000', 'road_ambient_dyno_drive_winter_030410_144000', 'road_ambient_highway_street_driving_diagnostics_031128_011320', 'road_ambient_dyno_drive_extended_short_021215_195320', 'road_ambient_highway_street_driving_long_050305_002000', 'road_ambient_dyno_drive_extended_long_040716_134640', 'road_ambient_dyno_drive_benign_anomaly_030804_082640', 'road_ambient_dyno_exercise_all_bits_030410_144000', 'road_ambient_dyno_reverse_040322_190000', 'road_ambient_dyno_drive_radio_infotainment_041109_063320', 'road_ambient_dyno_drive_basic_long_050305_002000'] \n",
      "\n",
      "13 ['correlated_masquerade_1_030804_082640', 'correlated_masquerade_2_031128_011320', 'correlated_masquerade_3_040322_190000', 'road_attack_max_speedometer_attack_1_masquerade_060215_054000', 'road_attack_max_speedometer_attack_2_masquerade_060611_002640', 'road_attack_max_speedometer_attack_3_masquerade_061004_181320', 'road_attack_max_engine_coolant_temp_attack_masquerade_041109_063320', 'road_attack_reverse_light_on_attack_1_masquerade_091205_030000', 'road_attack_reverse_light_on_attack_2_masquerade_100330_214640', 'road_attack_reverse_light_on_attack_3_masquerade_100724_153320', 'road_attack_reverse_light_off_attack_1_masquerade_080110_162000', 'road_attack_reverse_light_off_attack_2_masquerade_080505_110640', 'road_attack_reverse_light_off_attack_3_masquerade_080829_045320']\n"
     ]
    }
   ],
   "source": [
    "ground_truth_dbc_path = os.path.join(actt_path, \"metadata\", \"dbcs\", \"heuristic_labeled\", \"anonymized_020822_030640.dbc\")\n",
    "#testing_captures = [\"correlated_masquerade_1_030804_082640\", \"correlated_masquerade_2_031128_011320\", \"correlated_masquerade_3_040322_190000\"]\n",
    "\n",
    "# training_captures = [directory for directory in os.listdir(\"/home/cades/Projects/CAN/actt/data-cancaptures/\") if (\"road_ambient_dyno\" in directory) or (\"road_ambient_highway\" in directory)]\n",
    "training_captures = [directory for directory in os.listdir(\"/home/cloud/Projects/CAN/actt/data-cancaptures/\") if (\"road_ambient_dyno\" in directory) or (\"road_ambient_highway\" in directory)]\n",
    "print(len(training_captures), training_captures, \"\\n\")  \n",
    "\n",
    "testing_captures = [\"correlated_masquerade_1_030804_082640\", \"correlated_masquerade_2_031128_011320\", \"correlated_masquerade_3_040322_190000\", \n",
    "                    \"road_attack_max_speedometer_attack_1_masquerade_060215_054000\", \"road_attack_max_speedometer_attack_2_masquerade_060611_002640\", \n",
    "                    \"road_attack_max_speedometer_attack_3_masquerade_061004_181320\", \"road_attack_max_engine_coolant_temp_attack_masquerade_041109_063320\",\n",
    "                    \"road_attack_reverse_light_on_attack_1_masquerade_091205_030000\", \"road_attack_reverse_light_on_attack_2_masquerade_100330_214640\", \n",
    "                    \"road_attack_reverse_light_on_attack_3_masquerade_100724_153320\", \"road_attack_reverse_light_off_attack_1_masquerade_080110_162000\", \n",
    "                    \"road_attack_reverse_light_off_attack_2_masquerade_080505_110640\", \"road_attack_reverse_light_off_attack_3_masquerade_080829_045320\"]\n",
    "\n",
    "print(len(testing_captures), testing_captures) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15a97bcf-6188-463c-968f-cacf08e5c35f",
   "metadata": {},
   "source": [
    "## Obtain Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be80c927-83ff-4090-8f70-02b2fcfec8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "# with open(\"/home/cades/Projects/CAN/actt/data/capture_metadata.json\") as f:\n",
    "with open(\"/home/cloud/Projects/CAN/actt/data/capture_metadata.json\") as f:\n",
    "    attack_metadata = json.load(f)\n",
    "    \n",
    "# pprint(testing_captures)\n",
    "# pprint(attack_metadata)\n",
    "\n",
    "attack_metadata_keys = [\"correlated_signal_attack_1_masquerade\", \"correlated_signal_attack_2_masquerade\", \"correlated_signal_attack_3_masquerade\", \n",
    "                        \"max_speedometer_attack_1_masquerade\", \"max_speedometer_attack_2_masquerade\", \"max_speedometer_attack_3_masquerade\",\n",
    "                        \"max_engine_coolant_temp_attack_masquerade\", \"reverse_light_on_attack_1_masquerade\", \"reverse_light_on_attack_2_masquerade\",\n",
    "                        \"reverse_light_on_attack_3_masquerade\", \"reverse_light_off_attack_1_masquerade\", \"reverse_light_off_attack_2_masquerade\",\n",
    "                        \"reverse_light_off_attack_3_masquerade\"]\n",
    "\n",
    "print(len(attack_metadata_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7671774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated_signal_attack_1_masquerade\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'description': 'start from driving; accelerate; start injecting; car rolls to stop; stop injecting; accelerate',\n",
       " 'elapsed_sec': 33.101852,\n",
       " 'injection_data_str': '595945450000FFFF',\n",
       " 'injection_id': '0x6e0',\n",
       " 'injection_interval': [9.191851, 30.050109],\n",
       " 'modified': True,\n",
       " 'on_dyno': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(attack_metadata_keys[0])\n",
    "attack_metadata[\"correlated_signal_attack_1_masquerade\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b2bbd3d-59e1-494b-b880-3e56ede44699",
   "metadata": {},
   "source": [
    "## Experiments with Correlations of Same Signals"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08053218-b8d5-4628-bc90-87a3c263b5c6",
   "metadata": {},
   "source": [
    "## Extract Correlation Matrix From Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8923655-addf-4aa5-835d-e07ebbbf9b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12510, 337)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_multivar_ts, timepts, aid_signal_tups = from_capture_to_time_series(training_captures[-1], ground_truth_dbc_path)\n",
    "signal_multivar_ts.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9089db9-d462-4727-a6b4-c9bedd8a4158",
   "metadata": {},
   "source": [
    "## Partition Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c702b876-c616-47d8-89b0-54ec52536949",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = signal_multivar_ts.shape[0] # Consider the entire series\n",
    "offset = window\n",
    "partition_training = process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569de1f6-098a-4dc9-aeb4-04ab047090b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(partition_training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45f43252-3c24-4e53-8d09-c6041c435f8a",
   "metadata": {},
   "source": [
    "## Compute Correlation Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adcd5084-52bd-49a3-9d03-77fc983c9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "corr_matrices_training = compute_correlation_matrices(partition_training)\n",
    "print(len(corr_matrices_training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e91e812-003d-42d2-8927-5ee72218a9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14_0', '14_2', '51_0', '51_1', '51_2', '51_4', '51_5', '51_6',\n",
       "       '60_0', '60_1', '61_0', '61_1', '61_3', '61_4', '167_0', '167_3',\n",
       "       '167_4', '167_5', '167_6', '167_7', '167_8', '186_0', '186_1',\n",
       "       '186_6', '186_7', '192_0', '208_0', '208_1', '208_2', '208_3',\n",
       "       '208_4', '208_5', '293_2', '293_3', '293_5', '293_6', '304_1',\n",
       "       '339_3', '339_7', '339_11', '339_12', '354_0', '354_1', '354_2',\n",
       "       '354_3', '354_6', '403_1', '412_0', '412_1', '412_2', '412_3',\n",
       "       '412_4', '458_2', '470_0', '470_1', '470_2', '470_3', '470_4',\n",
       "       '470_5', '470_6', '470_7', '470_9', '470_12', '470_13', '519_1',\n",
       "       '519_2', '519_4', '519_5', '519_6', '519_7', '519_8', '519_9',\n",
       "       '526_0', '526_1', '526_2', '526_3', '560_0', '560_1', '560_2',\n",
       "       '560_3', '569_0', '569_1', '569_2', '569_3', '569_4', '622_5',\n",
       "       '628_0', '628_1', '628_2', '628_3', '628_4', '628_5', '628_6',\n",
       "       '628_7', '628_8', '628_9', '628_10', '628_11', '628_12', '628_13',\n",
       "       '628_14', '628_15', '661_0', '661_1', '675_0', '675_3', '675_4',\n",
       "       '675_6', '675_7', '675_8', '675_9', '675_10', '675_11', '692_1',\n",
       "       '722_1', '722_2', '722_4', '722_5', '722_7', '727_2', '738_4',\n",
       "       '738_6', '852_0', '852_2', '852_3', '870_0', '870_5', '961_2',\n",
       "       '961_3', '961_4', '996_0', '996_2', '1031_0', '1031_1', '1031_2',\n",
       "       '1031_3', '1031_4', '1031_5', '1031_6', '1031_9', '1031_10',\n",
       "       '1031_11', '1072_1', '1072_3', '1072_4', '1072_7', '1076_0',\n",
       "       '1076_1', '1076_2', '1076_3', '1076_4', '1124_2', '1124_3',\n",
       "       '1124_5', '1176_0', '1176_1', '1176_2', '1176_3', '1176_4',\n",
       "       '1225_0', '1225_5', '1225_6', '1225_8', '1255_0', '1255_1',\n",
       "       '1277_2', '1277_4', '1277_5', '1277_7', '1277_8', '1314_0',\n",
       "       '1314_1', '1314_2', '1314_3', '1399_1', '1408_0', '1408_1',\n",
       "       '1408_2', '1505_0', '1505_1', '1505_5', '1590_1', '1590_2',\n",
       "       '1590_3', '1590_4', '1628_1', '1628_2', '1628_3', '1628_4',\n",
       "       '1628_5', '1628_7', '1634_0', '1634_1', '1644_5', '1668_0',\n",
       "       '1668_1', '1668_2', '1668_4', '1668_5', '1694_1', '1694_2',\n",
       "       '1694_3', '1694_4', '1760_0', '1760_1', '1760_2', '1760_3',\n",
       "       '1788_3', '1788_6', '1788_8', '1788_9'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrices_training[0].columns.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c03b22-f7fc-4c6e-ac2f-2938376a451c",
   "metadata": {},
   "source": [
    "## Extract Correlation Matrix From Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d614bc7f-d706-42ff-b3ad-c8557d2204ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correlated_masquerade_1_030804_082640',\n",
       " 'correlated_masquerade_2_031128_011320',\n",
       " 'correlated_masquerade_3_040322_190000',\n",
       " 'road_attack_max_speedometer_attack_1_masquerade_060215_054000',\n",
       " 'road_attack_max_speedometer_attack_2_masquerade_060611_002640',\n",
       " 'road_attack_max_speedometer_attack_3_masquerade_061004_181320',\n",
       " 'road_attack_max_engine_coolant_temp_attack_masquerade_041109_063320',\n",
       " 'road_attack_reverse_light_on_attack_1_masquerade_091205_030000',\n",
       " 'road_attack_reverse_light_on_attack_2_masquerade_100330_214640',\n",
       " 'road_attack_reverse_light_on_attack_3_masquerade_100724_153320',\n",
       " 'road_attack_reverse_light_off_attack_1_masquerade_080110_162000',\n",
       " 'road_attack_reverse_light_off_attack_2_masquerade_080505_110640',\n",
       " 'road_attack_reverse_light_off_attack_3_masquerade_080829_045320']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_captures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74b08d31-89a8-4936-9fe7-dbd487fb8a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_multivar_ts, timepts, aid_signal_tups = from_capture_to_time_series(testing_captures[0], ground_truth_dbc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5f8cf8-e342-4bb9-be9e-24e50e4912ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timepts[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3efd98d9-da5c-43f6-8c74-e837bd364f61",
   "metadata": {},
   "source": [
    "## Partition Testing Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45d98f9-909d-4e61-a4cb-5676c28e5e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_testing = process_multivariate_signals(signal_multivar_ts, aid_signal_tups, 50, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b850bff-3517-4d09-9abc-0d917eed7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(partition_testing))\n",
    "#partition_testing[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7135fb3-8050-4512-9a6b-5c57f9346465",
   "metadata": {},
   "source": [
    "## Compute Correlation Matrices Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd6d3207-1350-4b75-8e88-1d457731eadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrices_testing = compute_correlation_matrices(partition_testing)\n",
    "len(corr_matrices_testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dfd73b0-b7bb-4e4d-83f5-f47083340b9e",
   "metadata": {},
   "source": [
    "## Create Time Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14019e84-9aa8-45f7-bed7-c787154e2fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 25 [(0, 10), (1, 11), (2, 12), (3, 13), (4, 14), (5, 15), (6, 16), (7, 17), (8, 18), (9, 19), (10, 20), (11, 21), (12, 22), (13, 23), (14, 24), (15, 25), (16, 26), (17, 27), (18, 28), (19, 29), (20, 30), (21, 31), (22, 32), (23, 33), (24, 34)]\n"
     ]
    }
   ],
   "source": [
    "total_length = int(np.ceil(timepts[-1]))   \n",
    "window = 10\n",
    "offset = 1        \n",
    "        \n",
    "intervals_testing = create_time_intervals(total_length, window, offset)\n",
    "    \n",
    "print(total_length, len(intervals_testing), intervals_testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3abe4cd-f580-4a0d-8e71-247bfe437287",
   "metadata": {},
   "source": [
    "## Hypothesis Testing (Single Attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56585b0c-ae8e-4ae6-ae27-24992f64b415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  correlated_signal_attack_1_masquerade\n",
      "intervals:  331\n",
      "total length (s):  33.9\n",
      "attack interval (s):  9.191851 30.050109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330/330 [00:00<00:00, 344.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 13, tn: 107, fp: 4, fn: 206\n",
      "precision: 0.765, recall: 0.059, f1: 0.110, fpr: 0.036, fnr: 0.941, mcc: 0.050\n",
      "positive_intervals: 219.000, negative_intervals: 111.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "signals_training = corr_matrices_training[0].columns.values\n",
    "\n",
    "window = 10\n",
    "offset = 1\n",
    "\n",
    "print(\"Processing: \", attack_metadata_keys[0])\n",
    "signal_multivar_ts, timepts, aid_signal_tups = from_capture_to_time_series(testing_captures[0], ground_truth_dbc_path)\n",
    "\n",
    "partition_testing = process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window, offset) # Partition time series\n",
    "print(\"intervals: \", len(partition_testing))\n",
    "\n",
    "# display(partition_testing[0])\n",
    "# display(partition_testing[1])\n",
    "# display(partition_testing[-1])\n",
    "\n",
    "corr_matrices_testing = compute_correlation_matrices(partition_testing) # Compute Correlations\n",
    "\n",
    "# total_length = int(np.ceil(timepts[-1])) \n",
    "total_length = timepts[-1]\n",
    "print(\"total length (s): \", total_length) \n",
    "intervals_testing = create_time_intervals(total_length, window/10, offset/10)\n",
    "print(\"attack interval (s): \", attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0], attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])\n",
    "\n",
    "tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "for index_interval in tqdm(range(len(intervals_testing))):\n",
    "    \n",
    "    # Compute signal names intersection\n",
    "    signals_testing = corr_matrices_testing[index_interval].columns.values\n",
    "    signal_names_intersection = list(set(signals_training).intersection(set(signals_testing)))\n",
    "    \n",
    "    # Filter correlation matrices by common names\n",
    "    corr_matrix_1 = corr_matrices_training[0].loc[signal_names_intersection, signal_names_intersection]\n",
    "    corr_matrix_2 = corr_matrices_testing[index_interval].loc[signal_names_intersection, signal_names_intersection]\n",
    "    \n",
    "    # Do hypothesis test\n",
    "    spearman_test = spearmanr(upper(corr_matrix_1), upper(corr_matrix_2))\n",
    "    # print((i, corr_matrix_1.shape[0], spearman_test[0], spearman_test[1]))\n",
    "    \n",
    "    if spearman_test[1] > 0.05: # positive detection\n",
    "        if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0])\n",
    "               or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])\n",
    "                   or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])):\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "    else: # negative detection\n",
    "        if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0])\n",
    "               or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])\n",
    "                   or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])):\n",
    "            fn += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "            \n",
    "# precision\n",
    "if tp + fp != 0:            \n",
    "    precision = tp/(tp + fp)\n",
    "else:\n",
    "    precision = np.nan\n",
    "\n",
    "# recall\n",
    "if tp + fn != 0:\n",
    "    recall = tp/(tp + fn)\n",
    "else:\n",
    "    recall = np.nan\n",
    "\n",
    "# f1\n",
    "if precision + recall != 0:\n",
    "    f1 = 2*((precision*recall)/(precision + recall))\n",
    "\n",
    "else:\n",
    "    f1 = np.nan\n",
    "\n",
    "# fpr\n",
    "if fp + tn != 0:\n",
    "    fpr = fp/(fp + tn)\n",
    "else:\n",
    "    fpr = np.nan\n",
    "\n",
    "# fnr\n",
    "if fn + tp != 0:\n",
    "    fnr = fn/(fn + tp)\n",
    "else:\n",
    "    fnr = np.nan\n",
    "\n",
    "# mcc\n",
    "if (tp+fp == 0) or (tp+fn == 0) or (tn+fp == 0) or (tn+fn == 0):\n",
    "    mcc = (tp*tn) - (fp*fn)\n",
    "else:\n",
    "    mcc = (tp*tn - fp*fn)/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "\n",
    "print(f\"tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}\")\n",
    "print(f\"precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}, fpr: {fpr:.3f}, fnr: {fnr:.3f}, mcc: {mcc:.3f}\")\n",
    "print(f\"positive_intervals: {tp+fn:.3f}, negative_intervals: {tn+fp:.3f}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85c62da7-bf07-4dd6-81de-dbe114033d92",
   "metadata": {},
   "source": [
    "## Hypothesis Testing (All Attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93a3139d-734c-41c9-b785-f0ba05c342b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  correlated_signal_attack_1_masquerade\n",
      "intervals:  331\n",
      "total length (s):  33.9\n",
      "attack interval (s):  9.191851 30.050109\n",
      "tp: 13, tn: 107, fp: 4, fn: 206\n",
      "precision: 0.765, recall: 0.059, f1: 0.110, fpr: 0.036, fnr: 0.941, mcc: 0.050\n",
      "positive_intervals: 219.000, negative_intervals: 111.000\n",
      "\n",
      "Processing:  correlated_signal_attack_2_masquerade\n",
      "intervals:  281\n",
      "total length (s):  28.9\n",
      "attack interval (s):  6.830477 28.225908\n",
      "tp: 1, tn: 49, fp: 10, fn: 220\n",
      "precision: 0.091, recall: 0.005, f1: 0.009, fpr: 0.169, fnr: 0.995, mcc: -0.346\n",
      "positive_intervals: 221.000, negative_intervals: 59.000\n",
      "\n",
      "Processing:  correlated_signal_attack_3_masquerade\n",
      "intervals:  161\n",
      "total length (s):  16.9\n",
      "attack interval (s):  4.318482 16.95706\n",
      "tp: 32, tn: 29, fp: 5, fn: 95\n",
      "precision: 0.865, recall: 0.252, f1: 0.390, fpr: 0.147, fnr: 0.748, mcc: 0.102\n",
      "positive_intervals: 127.000, negative_intervals: 34.000\n",
      "\n",
      "Processing:  max_speedometer_attack_1_masquerade\n",
      "intervals:  881\n",
      "total length (s):  88.9\n",
      "attack interval (s):  42.009204 66.449011\n",
      "tp: 0, tn: 620, fp: 7, fn: 254\n",
      "precision: 0.000, recall: 0.000, f1: nan, fpr: 0.011, fnr: 1.000, mcc: -0.057\n",
      "positive_intervals: 254.000, negative_intervals: 627.000\n",
      "\n",
      "Processing:  max_speedometer_attack_2_masquerade\n",
      "intervals:  591\n",
      "total length (s):  59.9\n",
      "attack interval (s):  16.009225 47.408246\n",
      "tp: 13, tn: 244, fp: 22, fn: 311\n",
      "precision: 0.371, recall: 0.040, f1: 0.072, fpr: 0.083, fnr: 0.960, mcc: -0.090\n",
      "positive_intervals: 324.000, negative_intervals: 266.000\n",
      "\n",
      "Processing:  max_speedometer_attack_3_masquerade\n",
      "intervals:  861\n",
      "total length (s):  86.9\n",
      "attack interval (s):  9.516489 70.587285\n",
      "tp: 25, tn: 217, fp: 24, fn: 595\n",
      "precision: 0.510, recall: 0.040, f1: 0.075, fpr: 0.100, fnr: 0.960, mcc: -0.115\n",
      "positive_intervals: 620.000, negative_intervals: 241.000\n",
      "\n",
      "Processing:  max_engine_coolant_temp_attack_masquerade\n",
      "intervals:  251\n",
      "total length (s):  25.9\n",
      "attack interval (s):  19.979078 24.170183\n",
      "tp: 0, tn: 197, fp: 1, fn: 52\n",
      "precision: 0.000, recall: 0.000, f1: nan, fpr: 0.005, fnr: 1.000, mcc: -0.032\n",
      "positive_intervals: 52.000, negative_intervals: 198.000\n",
      "\n",
      "Processing:  reverse_light_on_attack_1_masquerade\n",
      "intervals:  541\n",
      "total length (s):  54.9\n",
      "attack interval (s):  18.929177 38.836015\n",
      "tp: 0, tn: 331, fp: 0, fn: 209\n",
      "precision: nan, recall: 0.000, f1: nan, fpr: 0.000, fnr: 1.000, mcc: 0.000\n",
      "positive_intervals: 209.000, negative_intervals: 331.000\n",
      "\n",
      "Processing:  reverse_light_on_attack_2_masquerade\n",
      "intervals:  721\n",
      "total length (s):  72.9\n",
      "attack interval (s):  20.407134 57.297253\n",
      "tp: 9, tn: 328, fp: 14, fn: 369\n",
      "precision: 0.391, recall: 0.024, f1: 0.045, fpr: 0.041, fnr: 0.976, mcc: -0.049\n",
      "positive_intervals: 378.000, negative_intervals: 342.000\n",
      "\n",
      "Processing:  reverse_light_on_attack_3_masquerade\n",
      "intervals:  641\n",
      "total length (s):  64.9\n",
      "attack interval (s):  23.070278 46.580686\n",
      "tp: 7, tn: 391, fp: 4, fn: 238\n",
      "precision: 0.636, recall: 0.029, f1: 0.055, fpr: 0.010, fnr: 0.971, mcc: 0.069\n",
      "positive_intervals: 245.000, negative_intervals: 395.000\n",
      "\n",
      "Processing:  reverse_light_off_attack_1_masquerade\n",
      "intervals:  281\n",
      "total length (s):  28.9\n",
      "attack interval (s):  16.627923 23.347311\n",
      "tp: 12, tn: 183, fp: 20, fn: 65\n",
      "precision: 0.375, recall: 0.156, f1: 0.220, fpr: 0.099, fnr: 0.844, mcc: 0.080\n",
      "positive_intervals: 77.000, negative_intervals: 203.000\n",
      "\n",
      "Processing:  reverse_light_off_attack_2_masquerade\n",
      "intervals:  401\n",
      "total length (s):  40.9\n",
      "attack interval (s):  13.168608 36.87663\n",
      "tp: 62, tn: 134, fp: 19, fn: 185\n",
      "precision: 0.765, recall: 0.251, f1: 0.378, fpr: 0.124, fnr: 0.749, mcc: 0.153\n",
      "positive_intervals: 247.000, negative_intervals: 153.000\n",
      "\n",
      "Processing:  reverse_light_off_attack_3_masquerade\n",
      "intervals:  571\n",
      "total length (s):  57.9\n",
      "attack interval (s):  16.524085 40.862015\n",
      "tp: 36, tn: 293, fp: 24, fn: 217\n",
      "precision: 0.600, recall: 0.142, f1: 0.230, fpr: 0.076, fnr: 0.858, mcc: 0.108\n",
      "positive_intervals: 253.000, negative_intervals: 317.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = 10\n",
    "offset = 1 \n",
    "signals_training = corr_matrices_training[0].columns.values\n",
    "\n",
    "for index_attack in range(len(attack_metadata_keys)):\n",
    "\n",
    "    print(\"Processing: \", attack_metadata_keys[index_attack])\n",
    "    signal_multivar_ts, timepts, aid_signal_tups = from_capture_to_time_series(testing_captures[index_attack], ground_truth_dbc_path)\n",
    "    \n",
    "    partition_testing = process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window, offset) # Partition time series\n",
    "    print(\"intervals: \", len(partition_testing))\n",
    "\n",
    "    # display(partition_testing[0])\n",
    "    # display(partition_testing[1])\n",
    "    # display(partition_testing[-1])\n",
    "    \n",
    "    corr_matrices_testing = compute_correlation_matrices(partition_testing) # Compute Correlations\n",
    "    \n",
    "    # total_length = int(np.ceil(timepts[-1])) \n",
    "    total_length = timepts[-1]\n",
    "    print(\"total length (s): \", total_length) \n",
    "    intervals_testing = create_time_intervals(total_length, window/10, offset/10)\n",
    "    print(\"attack interval (s): \", attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0], attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])\n",
    "    \n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "    for index_interval in range(len(intervals_testing)):\n",
    "\n",
    "        # Compute signal names intersection\n",
    "        signals_testing = corr_matrices_testing[index_interval].columns.values\n",
    "        signal_names_intersection = list(set(signals_training).intersection(set(signals_testing)))\n",
    "\n",
    "        # Filter correlation matrices by common names\n",
    "        corr_matrix_1 = corr_matrices_training[0].loc[signal_names_intersection, signal_names_intersection]\n",
    "        corr_matrix_2 = corr_matrices_testing[index_interval].loc[signal_names_intersection, signal_names_intersection]\n",
    "\n",
    "        # Do hypothesis test\n",
    "        spearman_test = spearmanr(upper(corr_matrix_1), upper(corr_matrix_2))\n",
    "        # print((i, corr_matrix_1.shape[0], spearman_test[0], spearman_test[1]))\n",
    "\n",
    "        if spearman_test[1] > 0.05: # positive detection\n",
    "            if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0])\n",
    "                   or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])\n",
    "                       or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else: # negative detection\n",
    "            if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0])\n",
    "                   or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])\n",
    "                       or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])):\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    # precision\n",
    "    if tp + fp != 0:            \n",
    "        precision = tp/(tp + fp)\n",
    "    else:\n",
    "        precision = np.nan\n",
    "        \n",
    "    # recall\n",
    "    if tp + fn != 0:\n",
    "        recall = tp/(tp + fn)\n",
    "    else:\n",
    "        recall = np.nan\n",
    "        \n",
    "    # f1\n",
    "    if precision + recall != 0:\n",
    "        f1 = 2*((precision*recall)/(precision + recall))\n",
    "        \n",
    "    else:\n",
    "        f1 = np.nan\n",
    "        \n",
    "    # fpr\n",
    "    if fp + tn != 0:\n",
    "        fpr = fp/(fp + tn)\n",
    "    else:\n",
    "        fpr = np.nan\n",
    "\n",
    "    # fnr\n",
    "    if fn + tp != 0:\n",
    "        fnr = fn/(fn + tp)\n",
    "    else:\n",
    "        fnr = np.nan\n",
    "\n",
    "    # mcc\n",
    "    if (tp+fp == 0) or (tp+fn == 0) or (tn+fp == 0) or (tn+fn == 0):\n",
    "        mcc = (tp*tn) - (fp*fn)\n",
    "    else:\n",
    "        mcc = (tp*tn - fp*fn)/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "\n",
    "    print(f\"tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}\")\n",
    "    print(f\"precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}, fpr: {fpr:.3f}, fnr: {fnr:.3f}, mcc: {mcc:.3f}\")\n",
    "    print(f\"positive_intervals: {tp+fn:.3f}, negative_intervals: {tn+fp:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36740e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "can-bus-py-38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "45b264e09b14a9213e177c21a39e9d77d1b55e54df33475b814f14646fc04131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
