{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbc08f50-468f-4282-86d8-daa83faca073",
   "metadata": {},
   "source": [
    "## Purpose"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02a42602-e834-4850-99e1-5204ab1c38de",
   "metadata": {},
   "source": [
    "To compute the ML performance of the proposed method in near real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b76ffd-67e4-4633-937c-d8a14f6d0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import CAN_objects.aid_message\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "actt_path = os.path.join(os.path.join(os.path.expanduser(\"~\"), \"Projects\", \"CAN\", \"actt\"))\n",
    "os.chdir(actt_path)\n",
    "sys.path.insert(0, \"src\") # add src folder to path so that files from this folder can be imported\n",
    "\n",
    "from generalFunctions import unpickle\n",
    "import subprocess\n",
    "\n",
    "import importlib\n",
    "importlib.reload(CAN_objects.aid_message)\n",
    "from init_cancapture_from_canlog import init_cancap\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from CAN_objects.capture import MappedCapture, MatchedCapture\n",
    "import math\n",
    "from scipy.cluster.hierarchy import single, complete, average, ward, dendrogram, linkage, fcluster\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "from clusim.clustering import Clustering, remap2match\n",
    "import clusim.sim as sim\n",
    "\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from scipy.stats import shapiro, mannwhitneyu, ttest_ind, spearmanr\n",
    "from sklearn.preprocessing import normalize, scale, MinMaxScaler, StandardScaler\n",
    "\n",
    "from statistics import mode\n",
    "from bisect import bisect_left"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5139d795-5d61-4d58-b89a-60be905a32cf",
   "metadata": {},
   "source": [
    "## Enable the Use of Functions From the Detect Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e912d5-a9c0-492d-b7e5-eacf63fa46be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cloud/Projects/CAN/actt\n"
     ]
    }
   ],
   "source": [
    "# sys.path.insert(0, \"/home/cades/Projects/CAN/detect/\") # add detect folder to path so that files from this folder can be imported\n",
    "sys.path.insert(0, \"/home/cloud/Projects/CAN/detect/\") # add detect folder to path so that files from this folder can be imported\n",
    "import signal_based_preprocess_functions\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "14463891-cf80-4218-ba7d-8f2207cd2c28",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d1e7d8-fda7-4638-9510-f53dc3f381eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_capture_to_time_series(cap, ground_truth_dbc_path):\n",
    "    \n",
    "    signal_multivar_ts, timepts, aid_signal_tups = signal_based_preprocess_functions.capture_to_mv_signal_timeseries(cap, ground_truth_dbc_path)\n",
    "\n",
    "    return signal_multivar_ts, timepts, aid_signal_tups\n",
    "\n",
    "\n",
    "def from_captures_to_time_series(cap_1, cap_2, ground_truth_dbc_path):\n",
    "        \n",
    "    signal_multivar_ts_1, timepts_1, aid_signal_tups_1 = signal_based_preprocess_functions.capture_to_mv_signal_timeseries(cap_1, ground_truth_dbc_path)\n",
    "    signal_multivar_ts_2, timepts_2, aid_signal_tups_2 = signal_based_preprocess_functions.capture_to_mv_signal_timeseries(cap_2, ground_truth_dbc_path)\n",
    "\n",
    "    return signal_multivar_ts_1, timepts_1, aid_signal_tups_1, signal_multivar_ts_2, timepts_2, aid_signal_tups_2\n",
    "\n",
    "\n",
    "def remove_constant_signals(signal_multivar_ts):\n",
    "    return signal_multivar_ts[:, ~np.all(signal_multivar_ts[1:] == signal_multivar_ts[:-1], axis=0)]\n",
    "\n",
    "\n",
    "def partition_time_series(signal_multivar_ts, window_length, offset):\n",
    "    \n",
    "    n = signal_multivar_ts.shape[0]\n",
    "    i = 0\n",
    "    partition = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition.append(signal_multivar_ts[i: i + window_length,:])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition.append(signal_multivar_ts[i:n,:])\n",
    "        \n",
    "    return partition\n",
    "    \n",
    "    \n",
    "def process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window_length, offset):\n",
    "    \n",
    "    # First dataframe\n",
    "    # Convert matrix of time series into a dataframe\n",
    "    df = pd.DataFrame({f\"{tup[0]}_{tup[1]}\": signal_multivar_ts[:,index] for index, tup in enumerate(aid_signal_tups)})\n",
    "    # display(df)\n",
    "\n",
    "    # Remove columns with constant values\n",
    "    df = df.loc[:, (df != df.iloc[0]).any()] \n",
    "    # display(df)\n",
    "    \n",
    "    # Stadarization\n",
    "    # df_standardized = (df-df.mean())/df.std()\n",
    "    df_standardized = df\n",
    "    # display(df_standardized)\n",
    "    \n",
    "    # Partition of data frames\n",
    "    n = df_standardized.shape[0]\n",
    "    i = 0\n",
    "    partition = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition.append(df_standardized.iloc[i:i + window_length, :])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition.append(df_standardized.iloc[i:n, :])\n",
    "        \n",
    "    return partition\n",
    "\n",
    "\n",
    "def process_multiple_multivariate_signals(signal_multivar_ts_1, aid_signal_tups_1, signal_multivar_ts_2, aid_signal_tups_2, window_length, offset):\n",
    "    \n",
    "    # First dataframe\n",
    "    # Convert matrix of time series into a dataframe\n",
    "    df_1 = pd.DataFrame({f\"{tup[0]}_{tup[1]}\": signal_multivar_ts_1[:,index] for index, tup in enumerate(aid_signal_tups_1)})\n",
    "    # display(df)\n",
    "    print(df_1.shape)\n",
    "\n",
    "    # Remove columns with constant values\n",
    "    df_1 = df_1.loc[:, (df_1 != df_1.iloc[0]).any()] \n",
    "    # display(df)\n",
    "    \n",
    "    # Stadarization\n",
    "    df_1_standardized = (df_1-df_1.mean())/df_1.std()\n",
    "    # display(df_2_standardized)\n",
    "    \n",
    "    # Partition of data frames\n",
    "    n = df_1_standardized.shape[0]\n",
    "    i = 0\n",
    "    partition_1 = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition_1.append(df_1_standardized.iloc[i:i + window_length, :])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition_1.append(df_1_standardized.iloc[i:n, :])\n",
    "        \n",
    "        \n",
    "    # Second dataframe\n",
    "    # Convert matrix of time series into a dataframe\n",
    "    df_2 = pd.DataFrame({f\"{tup[0]}_{tup[1]}\": signal_multivar_ts_2[:,index] for index, tup in enumerate(aid_signal_tups_2)})\n",
    "    # display(df)\n",
    "    print(df_2.shape)\n",
    "\n",
    "    # Remove columns with constant values\n",
    "    df_2 = df_2.loc[:, (df_2 != df_2.iloc[0]).any()] \n",
    "    # display(df)\n",
    "    \n",
    "    # Stadarization\n",
    "    df_2_standardized = (df_2-df_2.mean())/df_2.std()\n",
    "    # display(df_2_standardized)\n",
    "    \n",
    "    # Partition of data frames\n",
    "    n = df_2_standardized.shape[0]\n",
    "    i = 0\n",
    "    partition_2 = []\n",
    "    \n",
    "    while (i + window_length) < n:\n",
    "        partition_2.append(df_2_standardized.iloc[i:i + window_length, :])\n",
    "        i = i + offset\n",
    "        \n",
    "    if i != n:\n",
    "        partition_2.append(df_2_standardized.iloc[i:n, :])\n",
    "        \n",
    "    return partition_1, partition_2\n",
    "\n",
    "\n",
    "def upper(df):\n",
    "    '''Returns the upper triangle of a correlation matrix.\n",
    "    You can use scipy.spatial.distance.squareform to recreate matrix from upper triangle.\n",
    "    Args:\n",
    "      df: pandas or numpy correlation matrix\n",
    "    Returns:\n",
    "      list of values from upper triangle\n",
    "    '''\n",
    "    try:\n",
    "        assert(type(df) == np.ndarray)\n",
    "    except:\n",
    "        if type(df) == pd.DataFrame:\n",
    "            df = df.values\n",
    "        else:\n",
    "            raise TypeError('Must be np.ndarray or pd.DataFrame')\n",
    "    mask = np.triu_indices(df.shape[0], k=1)\n",
    "    \n",
    "    return df[mask]\n",
    "\n",
    "\n",
    "\n",
    "def randomized_test_permutations(m1, m2):\n",
    "    \"\"\"Nonparametric permutation testing Monte Carlo\"\"\"\n",
    "    np.random.seed(0)\n",
    "    rhos = []\n",
    "    n_iter = 100\n",
    "    true_rho, _ = spearmanr(upper(m1), upper(m2))\n",
    "    # matrix permutation, shuffle the groups\n",
    "    m_ids = list(m1.columns)\n",
    "    m2_v = upper(m2)\n",
    "    for iter in range(n_iter):\n",
    "        np.random.shuffle(m_ids) # shuffle list \n",
    "        r, _ = spearmanr(upper(m1.loc[m_ids, m_ids]), m2_v)  \n",
    "        rhos.append(r)\n",
    "    perm_p = ((np.sum(np.abs(true_rho) <= np.abs(rhos)))+1)/(n_iter+1) # two-tailed test\n",
    "\n",
    "    return perm_p\n",
    "\n",
    "\n",
    "def compute_correlation_matrices(partition):\n",
    "    \n",
    "    corr_matrices = []\n",
    "\n",
    "    for df in partition:\n",
    "\n",
    "        # Remove columns with constant values\n",
    "        df = df.loc[:, (df != df.iloc[0]).any()] \n",
    "\n",
    "        # Compute correlation matrix\n",
    "        corr_matrices.append(df.corr(method=\"pearson\"))\n",
    "        \n",
    "    return corr_matrices\n",
    "\n",
    "\n",
    "def compute_similarity_from_correlation_matrices(corr_matrices):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(len(corr_matrices)-1):\n",
    "\n",
    "        # print(\"raw: \", corr_matrices[i].shape, corr_matrices[i+1].shape)\n",
    "\n",
    "        signal_names_1 = corr_matrices[i].columns.values\n",
    "        signal_names_2 = corr_matrices[i+1].columns.values\n",
    "        signal_names_intersection = list(set(signal_names_1).intersection(set(signal_names_2)))\n",
    "\n",
    "        df_1 = corr_matrices[i].loc[signal_names_intersection, signal_names_intersection] \n",
    "        df_2 = corr_matrices[i+1].loc[signal_names_intersection, signal_names_intersection]\n",
    "  \n",
    "        # print(\"pro: \", df_1.shape, df_2.shape, \"\\n\")\n",
    "\n",
    "        similarities.append((df_1.shape[0], spearmanr(upper(df_1), upper(df_2))[0], spearmanr(upper(df_1), upper(df_2))[1]))\n",
    "        \n",
    "    return similarities\n",
    "\n",
    "\n",
    "def compute_similarity_from_multiple_correlation_matrices(corr_matrices_1, corr_matrices_2):\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    if len(corr_matrices_1) <= len(corr_matrices_2):\n",
    "        corr_matrices_reference = corr_matrices_1\n",
    "    else:\n",
    "        corr_matrices_reference = corr_matrices_2\n",
    "        \n",
    "    print(len(corr_matrices_reference))\n",
    "            \n",
    "    for i in range(len(corr_matrices_reference)):\n",
    "\n",
    "        # print(\"raw: \", corr_matrices[i].shape, corr_matrices[i+1].shape)\n",
    "\n",
    "        signal_names_1 = corr_matrices_1[i].columns.values\n",
    "        signal_names_2 = corr_matrices_2[i].columns.values\n",
    "        signal_names_intersection = list(set(signal_names_1).intersection(set(signal_names_2)))\n",
    "\n",
    "        df_1 = corr_matrices_1[i].loc[signal_names_intersection, signal_names_intersection] \n",
    "        df_2 = corr_matrices_2[i].loc[signal_names_intersection, signal_names_intersection]\n",
    "  \n",
    "        # print(\"pro: \", df_1.shape, df_2.shape, \"\\n\")\n",
    "\n",
    "        # similarities.append((df_1.shape[0], spearmanr(upper(df_1), upper(df_2))[0], spearmanr(upper(df_1), upper(df_2))[1]))\n",
    "        \n",
    "        correlation = spearmanr(upper(df_1), upper(df_2))[0]\n",
    "        p_value = spearmanr(upper(df_1), upper(df_2))[1]\n",
    "        \n",
    "        if p_value > 0.05:\n",
    "            similarities.append((i, correlation, p_value))\n",
    "        else:\n",
    "            similarities.append(i)\n",
    "            \n",
    "        \n",
    "    return similarities\n",
    "\n",
    "\n",
    "def create_time_intervals(start_time, end_time, window, offset):\n",
    "\n",
    "    intervals = []\n",
    "    # window = 100*window\n",
    "    # offset = 0.1*offset\n",
    "    \n",
    "    for i in np.arange(start_time, end_time - window + 1, offset, dtype=float):\n",
    "        intervals.append((i, i + window))\n",
    "\n",
    "    if i + window < end_time:\n",
    "        intervals.append((i + offset, end_time))\n",
    "\n",
    "    return intervals  \n",
    "\n",
    "\n",
    "def _bisect_left_mod(signal_times, t_interp):\n",
    "    idx = bisect_left(signal_times,t_interp)\n",
    "    if idx > 0:\n",
    "        return idx - 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def interpolate_time_series(id_dic, timepts):\n",
    "    interp_vals = []\n",
    "\n",
    "    for id, signal_dic in id_dic.items():\n",
    "\n",
    "        for signal_id, payload in signal_dic.items():\n",
    "\n",
    "            interp_signals = []\n",
    "\n",
    "            for t in timepts:\n",
    "\n",
    "                interp_signals.append(payload[1][_bisect_left_mod(payload[0], t)])\n",
    "                \n",
    "            interp_vals.append(interp_signals)\n",
    "\n",
    "    return np.swapaxes(np.vstack(interp_vals), 0, 1)\n",
    "\n",
    "\n",
    "def dic_to_mv_signal_timeseries(id_dic, max_start_time, min_end_time, min_hz_msgs=10):\n",
    "    step = 1000/min_hz_msgs # because SynCAN timestamps are in ms\n",
    "\n",
    "    timepts = np.arange(max_start_time, min_end_time, step) # to endure we have coverage for the time intervals in each of the IDs\n",
    "\n",
    "    signal_multivar_ts = interpolate_time_series(id_dic, timepts)\n",
    "\n",
    "    return signal_multivar_ts, timepts\n",
    "\n",
    "\n",
    "def reformat_synCAN_dataset(file_name, df, read_df=False):\n",
    "    if read_df == True:\n",
    "        df_original = pd.read_csv(\"/home/cloud/Projects/CAN/actt/data/SynCAN-Dataset/\" + file_name)\n",
    "    else:\n",
    "        df_original = df\n",
    "\n",
    "    diff_dic = {}\n",
    "    id_dic = {}\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    aid_signal_tups = []\n",
    "\n",
    "    # unique_ids = df_original.sort_values(by=[\"ID\"], ascending=True)[\"ID\"].unique()\n",
    "    unique_ids = [\"id\" + str(i) for i in np.arange(1, 11)]\n",
    "    # print(unique_ids)\n",
    "\n",
    "    for count_id, id in enumerate(unique_ids, start=1):\n",
    "\n",
    "        # Dropping missing columns\n",
    "        df = df_original[df_original[\"ID\"] == id].dropna(axis=1, how=\"all\")\n",
    "        # display(df)\n",
    "\n",
    "        # Time range\n",
    "        times = df[df[\"ID\"] == id].sort_values(by=[\"Time\"], ascending=True)[\"Time\"].to_numpy()\n",
    "        start, end = times[0], times[-1]\n",
    "        start_times.append(start)\n",
    "        end_times.append(end)\n",
    "        \n",
    "        # Time intervals\n",
    "        diffs = np.diff(times)\n",
    "        modes = mode(diffs)\n",
    "        \n",
    "        diff_dic[id] = diffs\n",
    "        unique = len(np.unique(diffs))\n",
    "\n",
    "        # print(f\"{id}, unique inter-arrival time: {unique}, mode: {modes}\") \n",
    "        # print(f\"start: {start}, end: {end}, duration (min): {(end-start)/60000}\\n\")\n",
    "        interval = np.arange(start, end, 100)\n",
    "        # print(len(interval), interval)\n",
    "\n",
    "        # Extract signal names\n",
    "        df = df.loc[:, df.columns.str.startswith(\"Signal\")]\n",
    "        signal_names = df.columns.to_numpy()\n",
    "        # print(signal_names)\n",
    "        \n",
    "        # Create dictionary of signals\n",
    "        signal_dic = {}\n",
    "        for count_signal, signal_name in enumerate(signal_names, start=0):\n",
    "            values = df[signal_name].to_numpy()\n",
    "            signal_dic[signal_name] = [times, values]\n",
    "\n",
    "            #print(count_id, count_signal)\n",
    "            aid_signal_tups.append((count_id, count_signal))\n",
    "\n",
    "        id_dic[id] = signal_dic\n",
    "\n",
    "    max_start_time = np.ceil(max(start_times))\n",
    "    min_end_time = np.floor(min(end_times))\n",
    "        \n",
    "    return id_dic, aid_signal_tups, max_start_time, min_end_time \n",
    "\n",
    "\n",
    "def binary_search(number, intervals):\n",
    "    # intervals.sort()\n",
    "    mid = len(intervals)//2  # a//b is in python3. Use len(intervals)/2 for python2\n",
    "    low, high = intervals[mid]\n",
    "\n",
    "    # print(number, mid, (low, high), \"intervals:\", intervals)\n",
    "    \n",
    "    if number > high and len(intervals) > 2:\n",
    "        # print(\"high\", intervals[mid+1:])\n",
    "        return binary_search(number, intervals[mid+1:])\n",
    "    elif number < low and len(intervals) > 2:\n",
    "        # print(\"low\", intervals[:mid])\n",
    "        return binary_search(number, intervals[:mid])\n",
    "    elif low <= number <= high:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65acf9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(22, [(1,11), (12,15), (17,19), (20,25)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "222ac358-1bc4-4761-a750-f79bc8ffd691",
   "metadata": {},
   "source": [
    "## Process SynCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9174ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Signal1_of_ID</th>\n",
       "      <th>Signal2_of_ID</th>\n",
       "      <th>Signal3_of_ID</th>\n",
       "      <th>Signal4_of_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550892e+07</td>\n",
       "      <td>id7</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550892e+07</td>\n",
       "      <td>id5</td>\n",
       "      <td>0.327077</td>\n",
       "      <td>0.931964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550893e+07</td>\n",
       "      <td>id1</td>\n",
       "      <td>0.621423</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550893e+07</td>\n",
       "      <td>id6</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550893e+07</td>\n",
       "      <td>id8</td>\n",
       "      <td>0.215771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150047</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id6</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150048</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.806563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150049</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id8</td>\n",
       "      <td>0.156707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150050</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id1</td>\n",
       "      <td>0.549564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150051</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id5</td>\n",
       "      <td>0.125041</td>\n",
       "      <td>0.388260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2150052 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label          Time   ID  Signal1_of_ID  Signal2_of_ID  \\\n",
       "0            0  8.550892e+07  id7       0.055714       0.750000   \n",
       "1            0  8.550892e+07  id5       0.327077       0.931964   \n",
       "2            0  8.550893e+07  id1       0.621423       0.750000   \n",
       "3            0  8.550893e+07  id6       0.921053       0.555556   \n",
       "4            0  8.550893e+07  id8       0.215771            NaN   \n",
       "...        ...           ...  ...            ...            ...   \n",
       "2150047      0  9.000939e+07  id6       0.394737       0.000000   \n",
       "2150048      0  9.000939e+07  id3       0.400000       0.806563   \n",
       "2150049      0  9.000939e+07  id8       0.156707            NaN   \n",
       "2150050      0  9.000939e+07  id1       0.549564       1.000000   \n",
       "2150051      0  9.000939e+07  id5       0.125041       0.388260   \n",
       "\n",
       "         Signal3_of_ID  Signal4_of_ID  \n",
       "0                  NaN            NaN  \n",
       "1                  NaN            NaN  \n",
       "2                  NaN            NaN  \n",
       "3                  NaN            NaN  \n",
       "4                  NaN            NaN  \n",
       "...                ...            ...  \n",
       "2150047            NaN            NaN  \n",
       "2150048            NaN            NaN  \n",
       "2150049            NaN            NaN  \n",
       "2150050            NaN            NaN  \n",
       "2150051            NaN            NaN  \n",
       "\n",
       "[2150052 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Time</th>\n",
       "      <th>ID</th>\n",
       "      <th>Signal1_of_ID</th>\n",
       "      <th>Signal2_of_ID</th>\n",
       "      <th>Signal3_of_ID</th>\n",
       "      <th>Signal4_of_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550892e+07</td>\n",
       "      <td>id7</td>\n",
       "      <td>0.055714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550892e+07</td>\n",
       "      <td>id5</td>\n",
       "      <td>0.327077</td>\n",
       "      <td>0.931964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550893e+07</td>\n",
       "      <td>id1</td>\n",
       "      <td>0.621423</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550893e+07</td>\n",
       "      <td>id6</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.550893e+07</td>\n",
       "      <td>id8</td>\n",
       "      <td>0.215771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150047</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id6</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150048</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id3</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.806563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150049</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id8</td>\n",
       "      <td>0.156707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150050</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id1</td>\n",
       "      <td>0.549564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150051</th>\n",
       "      <td>0</td>\n",
       "      <td>9.000939e+07</td>\n",
       "      <td>id5</td>\n",
       "      <td>0.125041</td>\n",
       "      <td>0.388260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2150052 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label          Time   ID  Signal1_of_ID  Signal2_of_ID  \\\n",
       "0            0  8.550892e+07  id7       0.055714       0.750000   \n",
       "1            0  8.550892e+07  id5       0.327077       0.931964   \n",
       "2            0  8.550893e+07  id1       0.621423       0.750000   \n",
       "3            0  8.550893e+07  id6       0.921053       0.555556   \n",
       "4            0  8.550893e+07  id8       0.215771            NaN   \n",
       "...        ...           ...  ...            ...            ...   \n",
       "2150047      0  9.000939e+07  id6       0.394737       0.000000   \n",
       "2150048      0  9.000939e+07  id3       0.400000       0.806563   \n",
       "2150049      0  9.000939e+07  id8       0.156707            NaN   \n",
       "2150050      0  9.000939e+07  id1       0.549564       1.000000   \n",
       "2150051      0  9.000939e+07  id5       0.125041       0.388260   \n",
       "\n",
       "         Signal3_of_ID  Signal4_of_ID  \n",
       "0                  NaN            NaN  \n",
       "1                  NaN            NaN  \n",
       "2                  NaN            NaN  \n",
       "3                  NaN            NaN  \n",
       "4                  NaN            NaN  \n",
       "...                ...            ...  \n",
       "2150047            NaN            NaN  \n",
       "2150048            NaN            NaN  \n",
       "2150049            NaN            NaN  \n",
       "2150050            NaN            NaN  \n",
       "2150051            NaN            NaN  \n",
       "\n",
       "[2150052 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_original = pd.read_csv(\"/home/cloud/Projects/CAN/actt/data/SynCAN-Dataset/test_normal.csv\")\n",
    "display(df_original)\n",
    "\n",
    "df_original =  df_original.sort_values(by=[\"Time\"], ascending=True)\n",
    "display(df_original)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f68f5be2",
   "metadata": {},
   "source": [
    "## Explore Each of the IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed4ec95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (2, 0), (2, 1), (2, 2), (3, 0), (3, 1), (4, 0), (5, 0), (5, 1), (6, 0), (6, 1), (7, 0), (7, 1), (8, 0), (9, 0), (10, 0), (10, 1), (10, 2), (10, 3)] 85508963.0 90009365.0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"test_normal.csv\"\n",
    "\n",
    "id_dic, aid_signal_tups, max_start_time, min_end_time = reformat_synCAN_dataset(file_name, _, True)\n",
    "print(aid_signal_tups, max_start_time, min_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cedd065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Signal1_of_ID': [array([85508925.3252, 85508940.3252, 85508955.3252, ..., 90009362.9808,\n",
       "         90009377.9808, 90009392.9808]),\n",
       "  array([0.62142346, 0.62142346, 0.62142346, ..., 0.54940344, 0.54948349,\n",
       "         0.54956354])],\n",
       " 'Signal2_of_ID': [array([85508925.3252, 85508940.3252, 85508955.3252, ..., 90009362.9808,\n",
       "         90009377.9808, 90009392.9808]),\n",
       "  array([0.75, 1.  , 0.  , ..., 0.5 , 0.75, 1.  ])]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_dic[\"id1\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86febf18",
   "metadata": {},
   "source": [
    "## Interpolate signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "836a521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_multivar_ts, timepts = dic_to_mv_signal_timeseries(id_dic, max_start_time, min_end_time, min_hz_msgs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9f875ca-1784-437a-b7e2-b458de25ff0f",
   "metadata": {},
   "source": [
    "## Experiments on a Single Capture File (Distribution-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2ff2915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450041, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_multivar_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6a741e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85508963., 85508973., 85508983., ..., 90009343., 90009353.,\n",
       "       90009363.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb226d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0),\n",
       " (1, 1),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (4, 0),\n",
       " (5, 0),\n",
       " (5, 1),\n",
       " (6, 0),\n",
       " (6, 1),\n",
       " (7, 0),\n",
       " (7, 1),\n",
       " (8, 0),\n",
       " (9, 0),\n",
       " (10, 0),\n",
       " (10, 1),\n",
       " (10, 2),\n",
       " (10, 3)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aid_signal_tups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b454d01-0cc8-475f-8ebd-94b547bdfda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10., 10., 10., ..., 10., 10., 10.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(timepts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43d84a27",
   "metadata": {},
   "source": [
    "## Partition Time Series Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11a25f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0), (1, 1), (2, 0), (2, 1), (2, 2), (3, 0), (3, 1), (4, 0), (5, 0), (5, 1), (6, 0), (6, 1), (7, 0), (7, 1), (8, 0), (9, 0), (10, 0), (10, 1), (10, 2), (10, 3)] 85508963.0 90009365.0\n"
     ]
    }
   ],
   "source": [
    "file_name = \"test_normal.csv\"\n",
    "\n",
    "id_dic, aid_signal_tups, max_start_time, min_end_time = reformat_synCAN_dataset(file_name, _, True)\n",
    "print(aid_signal_tups, max_start_time, min_end_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75672a4d",
   "metadata": {},
   "source": [
    "## Interpolate Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "498faf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_frequency = 100\n",
    "signal_multivar_ts, timepts = dic_to_mv_signal_timeseries(id_dic, max_start_time, min_end_time, min_hz_msgs=sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bca9eb99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450041, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal_multivar_ts.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e1c1d05c",
   "metadata": {},
   "source": [
    "## Experiments Comparing Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a536d9a7-64f9-4724-b803-96f02d3599c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intervals:  44996\n",
      "total length (s):  4500.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44996/44996 [00:12<00:00, 3574.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp: 0, tn: 25106, fp: 19890, fn: 0\n",
      "precision: 0.000, recall: nan, f1: nan, fpr: 0.442, fnr: nan, mcc: 0.000\n",
      "positive_intervals: 0.000, negative_intervals: 44996.000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "window = 10\n",
    "offset = 1\n",
    "\n",
    "partition_testing = process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window, offset) # Partition time series\n",
    "print(\"intervals: \", len(partition_testing))\n",
    "\n",
    "# display(partition_testing[0])\n",
    "# display(partition_testing[1])\n",
    "\n",
    "corr_matrices_testing = compute_correlation_matrices(partition_testing) # Compute Correlations\n",
    "\n",
    "total_length = (int(np.ceil(timepts[-1])) - int(np.ceil(timepts[0])))/1000\n",
    "print(\"total length (s): \", total_length) \n",
    "\n",
    "intervals_testing = create_time_intervals(max_start_time, min_end_time, window*100, offset*100)\n",
    "# print(len(intervals_testing), intervals_testing[-10:])\n",
    "\n",
    "tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "for index_interval in tqdm(range(len(intervals_testing))):\n",
    "    \n",
    "    # print(index_interval)\n",
    "\n",
    "    # Get correlation matrices\n",
    "    corr_sample_testing = upper(corr_matrices_testing[index_interval])\n",
    "     \n",
    "    # Do hypothesis test\n",
    "    mannwhitneyu_test = mannwhitneyu(corr_sample_training, corr_sample_testing)\n",
    "    # print((index_interval, len(corr_sample_training), len(corr_sample_testing), mannwhitneyu_test[0], mannwhitneyu_test[1]))\n",
    "\n",
    "    # print(intervals_testing[index_interval][0], intervals_testing[index_interval][1], attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0], attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])\n",
    "\n",
    "    if mannwhitneyu_test[1] <= 0.05: # positive detection\n",
    "        # if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0])\n",
    "        #        or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])\n",
    "        #            or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])):\n",
    "        #     tp += 1\n",
    "        # else:\n",
    "        fp += 1\n",
    "    else: # negative detection\n",
    "        # if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0])\n",
    "        #        or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])\n",
    "        #            or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[0]][\"injection_interval\"][1])):\n",
    "        #     fn += 1\n",
    "        # else:\n",
    "        tn += 1\n",
    "            \n",
    "# precision\n",
    "if tp + fp != 0:            \n",
    "    precision = tp/(tp + fp)\n",
    "else:\n",
    "    precision = np.nan\n",
    "\n",
    "# recall\n",
    "if tp + fn != 0:\n",
    "    recall = tp/(tp + fn)\n",
    "else:\n",
    "    recall = np.nan\n",
    "\n",
    "# f1\n",
    "if precision + recall != 0:\n",
    "    f1 = 2*((precision*recall)/(precision + recall))\n",
    "\n",
    "else:\n",
    "    f1 = np.nan\n",
    "\n",
    "# fpr\n",
    "if fp + tn != 0:\n",
    "    fpr = fp/(fp + tn)\n",
    "else:\n",
    "    fpr = np.nan\n",
    "\n",
    "# fnr\n",
    "if fn + tp != 0:\n",
    "    fnr = fn/(fn + tp)\n",
    "else:\n",
    "    fnr = np.nan\n",
    "\n",
    "# mcc\n",
    "if (tp+fp == 0) or (tp+fn == 0) or (tn+fp == 0) or (tn+fn == 0):\n",
    "    mcc = (tp*tn) - (fp*fn)\n",
    "else:\n",
    "    mcc = (tp*tn - fp*fn)/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "\n",
    "print(f\"tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}\")\n",
    "print(f\"precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}, fpr: {fpr:.3f}, fnr: {fnr:.3f}, mcc: {mcc:.3f}\")\n",
    "print(f\"positive_intervals: {tp+fn:.3f}, negative_intervals: {tn+fp:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "552a2c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67506083.0, 67507025.0)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals_testing[-1]\n",
    "# len(corr_matrices_testing)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb01cb63-974f-40db-a138-3e9f511c1264",
   "metadata": {},
   "source": [
    "## Hypothesis Testing (All Attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbf884c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_plateau.csv',\n",
       " 'test_playback.csv',\n",
       " 'test_suppress.csv',\n",
       " 'test_flooding.csv',\n",
       " 'test_continuous.csv']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"/home/cloud/Projects/CAN/actt/data/SynCAN-Dataset/\" + \"dic_attack_intervals.json\", \"r\") as fp:\n",
    "    attack_metadata = json.load(fp)\n",
    "\n",
    "attack_metadata_keys = list(attack_metadata.keys())\n",
    "display(attack_metadata_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4392b492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[67537573.9491, 67543212.5544],\n",
       " [67583022.5544, 67587191.7058],\n",
       " [67626329.2547, 67631726.6324],\n",
       " [67659992.2329, 67664968.7447],\n",
       " [67705122.5544, 67711720.6978],\n",
       " [67748279.3292, 67755660.0302],\n",
       " [67797168.6874, 67805239.2455],\n",
       " [67838863.9985, 67845463.3372],\n",
       " [67868300.0494, 67872810.3555],\n",
       " [67909407.8584, 67914702.5544],\n",
       " [67936260.229, 67944196.2129],\n",
       " [67983217.4205, 67987670.4139],\n",
       " [68018806.2129, 68026993.2948],\n",
       " [68064918.2239, 68073030.5126],\n",
       " [68109892.4205, 68114887.1873],\n",
       " [68138626.2129, 68143842.5544],\n",
       " [68174908.4883, 68180262.5613],\n",
       " [68203715.4139, 68211634.3061],\n",
       " [68246468.0408, 68253966.8615],\n",
       " [68293417.1322, 68298532.9226],\n",
       " [68337555.975, 68342595.2881],\n",
       " [68377306.2129, 68385612.5544],\n",
       " [68412650.4139, 68419489.8597],\n",
       " [68442728.2221, 68448157.4205],\n",
       " [68481817.7363, 68489692.4205],\n",
       " [68528347.4205, 68535500.8989],\n",
       " [68565253.7535, 68572062.4963],\n",
       " [68599498.8265, 68606396.07],\n",
       " [68633023.7535, 68639802.7876],\n",
       " [68675342.2033, 68682286.4468],\n",
       " [68707568.8771, 68712758.3121],\n",
       " [68751304.9817, 68757858.1323],\n",
       " [68790436.2129, 68795655.1789],\n",
       " [68835648.3104, 68843506.2129],\n",
       " [68868793.7535, 68874521.9596],\n",
       " [68901215.4139, 68907919.9923],\n",
       " [68939229.9471, 68943517.4205],\n",
       " [68982523.8972, 68988913.7535],\n",
       " [69019045.2879, 69025059.9471],\n",
       " [69060725.9722, 69067445.4139],\n",
       " [69098274.2933, 69106266.2135],\n",
       " [69136420.7163, 69143333.4319],\n",
       " [69168065.9806, 69176360.9052],\n",
       " [69198722.183, 69207016.2129],\n",
       " [69239713.7535, 69245380.7095],\n",
       " [69275384.0161, 69282597.6481],\n",
       " [69320830.7095, 69326169.7165],\n",
       " [69366826.2129, 69373335.8719],\n",
       " [69408412.4205, 69415700.7076],\n",
       " [69445395.8813, 69453474.3512],\n",
       " [69485116.2129, 69492643.4373],\n",
       " [69527357.0853, 69532426.2129],\n",
       " [69568284.4553, 69575552.4716],\n",
       " [69616594.2079, 69622293.548],\n",
       " [69649070.4603, 69655882.6379],\n",
       " [69687613.0263, 69691886.0769],\n",
       " [69720406.2129, 69727063.2228],\n",
       " [69767866.2473, 69775636.2129],\n",
       " [69813230.4139, 69820429.8809],\n",
       " [69841812.1942, 69847328.2795],\n",
       " [69877344.3743, 69882427.8189],\n",
       " [69911413.3463, 69918374.1777],\n",
       " [69955419.2658, 69963095.3474],\n",
       " [69995181.7368, 70002966.8316],\n",
       " [70032847.9751, 70037692.4205],\n",
       " [70063972.4205, 70069865.4139],\n",
       " [70092859.537, 70100071.1173],\n",
       " [70141866.0033, 70148977.1649],\n",
       " [70184322.8674, 70191549.8238],\n",
       " [70231468.6024, 70239579.5885],\n",
       " [70267937.6621, 70273678.6446],\n",
       " [70303685.4139, 70309849.4285],\n",
       " [70349586.1112, 70356336.0144],\n",
       " [70393124.812, 70399874.6193],\n",
       " [70433015.4139, 70439899.4285],\n",
       " [70472774.6193, 70478353.7641],\n",
       " [70502900.4139, 70507670.0087],\n",
       " [70543061.4851, 70550336.567],\n",
       " [70576079.7852, 70580444.6193],\n",
       " [70610817.5055, 70618091.036],\n",
       " [70642304.97, 70649578.7312],\n",
       " [70678598.7622, 70686921.6031],\n",
       " [70725676.2599, 70732274.7675],\n",
       " [70769084.6193, 70775467.4205],\n",
       " [70802512.869, 70810354.6437],\n",
       " [70839132.1129, 70845704.1315],\n",
       " [70876742.739, 70883597.0318],\n",
       " [70914046.2599, 70919265.9719],\n",
       " [70942370.4139, 70947589.4501],\n",
       " [70969670.6296, 70974277.4205],\n",
       " [71002447.4205, 71008971.8951],\n",
       " [71036143.4525, 71044379.6904],\n",
       " [71078479.4501, 71082887.6069],\n",
       " [71108970.1101, 71114174.8013],\n",
       " [71147654.9245, 71152117.7797],\n",
       " [71177186.1115, 71181623.5587],\n",
       " [71210124.0507, 71216479.4501],\n",
       " [71252122.545, 71257263.9249],\n",
       " [71283773.0716, 71291196.4273],\n",
       " [71317087.4205, 71322755.4731],\n",
       " [71360956.8331, 71366925.833],\n",
       " [71401284.1361, 71405525.411],\n",
       " [71439847.7428, 71445275.1278],\n",
       " [71483317.4205, 71489660.4139],\n",
       " [71513608.4309, 71518288.0989],\n",
       " [71546563.477, 71553354.2478],\n",
       " [71575906.8331, 71580766.0126],\n",
       " [71620064.9245, 71625372.0885],\n",
       " [71655116.9047, 71660245.5544],\n",
       " [71697202.4205, 71702150.9136],\n",
       " [71724560.4139, 71730545.0636],\n",
       " [71762902.4205, 71769202.0518],\n",
       " [71797615.2298, 71804872.1534],\n",
       " [71845849.5029, 71853619.2387],\n",
       " [71882394.0815, 71887912.4205]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5638.6052999943495\n",
      "4169.151399999857\n",
      "5397.377700001001\n",
      "4976.511800006032\n",
      "6598.143399998546\n",
      "7380.701000005007\n",
      "8070.558100000024\n",
      "6599.338699996471\n",
      "4510.306099995971\n",
      "5294.695999994874\n",
      "7935.983899995685\n",
      "4452.993400007486\n",
      "8187.081900000572\n",
      "8112.288699999452\n",
      "4994.766800001264\n",
      "5216.3414999991655\n",
      "5354.072999998927\n",
      "7918.8921999931335\n",
      "7498.820699989796\n",
      "5115.790399998426\n",
      "5039.313100010157\n",
      "8306.341499999166\n",
      "6839.4457999914885\n",
      "5429.198399990797\n",
      "7874.684199988842\n",
      "7153.47840000689\n",
      "6808.74279999733\n",
      "6897.243499994278\n",
      "6779.03409999609\n",
      "6944.243499994278\n",
      "5189.434999987483\n",
      "6553.150600001216\n",
      "5218.966000005603\n",
      "7857.902500003576\n",
      "5728.206100001931\n",
      "6704.57840000093\n",
      "4287.4733999967575\n",
      "6389.856299996376\n",
      "6014.659199997783\n",
      "6719.441699996591\n",
      "7991.9201999902725\n",
      "6912.715599998832\n",
      "8294.92460000515\n",
      "8294.0298999995\n",
      "5666.956000000238\n",
      "7213.631999999285\n",
      "5339.006999999285\n",
      "6509.659000009298\n",
      "7288.28710000217\n",
      "8078.469899997115\n",
      "7527.224399998784\n",
      "5069.127599999309\n",
      "7268.0162999928\n",
      "5699.340099990368\n",
      "6812.177599996328\n",
      "4273.050600007176\n",
      "6657.009900003672\n",
      "7769.965599998832\n",
      "7199.466999992728\n",
      "5516.085299998522\n",
      "5083.4446000009775\n",
      "6960.831399992108\n",
      "7676.081599995494\n",
      "7785.094799995422\n",
      "4844.4453999996185\n",
      "5892.993400007486\n",
      "7211.58030000329\n",
      "7111.161600008607\n",
      "7226.956399992108\n",
      "8110.986099988222\n",
      "5740.982500001788\n",
      "6164.014599993825\n",
      "6749.9032000005245\n",
      "6749.807299986482\n",
      "6884.014599993825\n",
      "5579.144800007343\n",
      "4769.594799995422\n",
      "7275.081900000572\n",
      "4364.83409999311\n",
      "7273.530499994755\n",
      "7273.761199995875\n",
      "8322.84090000391\n",
      "6598.50759999454\n",
      "6382.801200002432\n",
      "7841.774700000882\n",
      "6572.018600001931\n",
      "6854.292800009251\n",
      "5219.711999997497\n",
      "5219.036200001836\n",
      "4606.790899991989\n",
      "6524.47460000217\n",
      "8236.23790000379\n",
      "4408.15680000186\n",
      "5204.691200003028\n",
      "4462.855199992657\n",
      "4437.447200000286\n",
      "6355.399400010705\n",
      "5141.379899993539\n",
      "7423.355700001121\n",
      "5668.0526000112295\n",
      "5968.999899998307\n",
      "4241.274900004268\n",
      "5427.385000005364\n",
      "6342.993400007486\n",
      "4679.668000012636\n",
      "6790.770799994469\n",
      "4859.179499998689\n",
      "5307.163999989629\n",
      "5128.649700000882\n",
      "4948.493100002408\n",
      "5984.649700000882\n",
      "6299.6313000023365\n",
      "7256.923600003123\n",
      "7769.735799998045\n",
      "5518.33900000155\n"
     ]
    }
   ],
   "source": [
    "display(attack_metadata['test_plateau.csv'])\n",
    "\n",
    "for interval in attack_metadata['test_plateau.csv']:\n",
    "    print(interval[1] - interval[0])\n",
    "\n",
    "#attack_metadata['test_plateau.csv'][0][1] - attack_metadata['test_plateau.csv'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00f027ec-835c-4713-b0c2-0de54a5629c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:  test_plateau.csv\n",
      "intervals:  44996\n",
      "total length (s):  4500.4\n",
      "tp: 2937, tn: 22119, fp: 15362, fn: 4578\n",
      "precision: 0.161, recall: 0.391, f1: 0.228, fpr: 0.410, fnr: 0.609, mcc: -0.014\n",
      "positive_intervals: 7515.000, negative_intervals: 37481.000\n",
      "\n",
      "Processing:  test_playback.csv\n",
      "intervals:  44996\n",
      "total length (s):  4500.4\n",
      "tp: 1942, tn: 22413, fp: 17962, fn: 2679\n",
      "precision: 0.098, recall: 0.420, f1: 0.158, fpr: 0.445, fnr: 0.580, mcc: -0.015\n",
      "positive_intervals: 4621.000, negative_intervals: 40375.000\n",
      "\n",
      "Processing:  test_suppress.csv\n",
      "intervals:  44996\n",
      "total length (s):  4500.4\n",
      "tp: 3675, tn: 20427, fp: 15931, fn: 4963\n",
      "precision: 0.187, recall: 0.425, f1: 0.260, fpr: 0.438, fnr: 0.575, mcc: -0.010\n",
      "positive_intervals: 8638.000, negative_intervals: 36358.000\n",
      "\n",
      "Processing:  test_flooding.csv\n",
      "intervals:  44996\n",
      "total length (s):  4500.4\n",
      "tp: 2547, tn: 22530, fp: 16134, fn: 3785\n",
      "precision: 0.136, recall: 0.402, f1: 0.204, fpr: 0.417, fnr: 0.598, mcc: -0.011\n",
      "positive_intervals: 6332.000, negative_intervals: 38664.000\n",
      "\n",
      "Processing:  test_continuous.csv\n",
      "intervals:  44996\n",
      "total length (s):  4500.4\n",
      "tp: 1865, tn: 22831, fp: 17525, fn: 2775\n",
      "precision: 0.096, recall: 0.402, f1: 0.155, fpr: 0.434, fnr: 0.598, mcc: -0.020\n",
      "positive_intervals: 4640.000, negative_intervals: 40356.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "window = 10\n",
    "offset = 1\n",
    "signals_training = corr_matrices_training[0].columns.values\n",
    "\n",
    "# print(signals_training)\n",
    "\n",
    "for index_attack in range(len(attack_metadata_keys)):\n",
    "\n",
    "    print(\"Processing: \", attack_metadata_keys[index_attack])\n",
    "\n",
    "    # signal_multivar_ts, timepts, aid_signal_tups = from_capture_to_time_series(testing_captures[index_attack], ground_truth_dbc_path) \n",
    "\n",
    "    id_dic, aid_signal_tups, max_start_time, min_end_time = reformat_synCAN_dataset(attack_metadata_keys[index_attack], _, True)\n",
    "    signal_multivar_ts, timepts = dic_to_mv_signal_timeseries(id_dic, max_start_time, min_end_time, min_hz_msgs=10)\n",
    "    \n",
    "    partition_testing = process_multivariate_signals(signal_multivar_ts, aid_signal_tups, window, offset) # Partition time series\n",
    "    print(\"intervals: \", len(partition_testing))\n",
    "    \n",
    "    # display(partition_testing[0])\n",
    "    # display(partition_testing[1])\n",
    "\n",
    "    corr_matrices_testing = compute_correlation_matrices(partition_testing) # Compute correlations\n",
    "    \n",
    "    total_length = (int(np.ceil(timepts[-1])) - int(np.ceil(timepts[0])))/1000 \n",
    "    print(\"total length (s): \", total_length)\n",
    "    intervals_testing = create_time_intervals(max_start_time, min_end_time, window*100, offset*100)\n",
    "    # print(len(intervals_testing), intervals_testing[:5], intervals_testing[-5:], \"\\n\")\n",
    "\n",
    "    # print(\"intervals testing: \", intervals_testing)\n",
    "    \n",
    "    tp, fp, fn, tn = 0, 0, 0, 0\n",
    "\n",
    "    for index_interval in range(len(intervals_testing)):\n",
    "\n",
    "        # Get correlation matrices\n",
    "        corr_sample_testing = upper(corr_matrices_testing[index_interval])\n",
    "\n",
    "        # Do hypothesis test\n",
    "        mannwhitneyu_test = mannwhitneyu(corr_sample_training, corr_sample_testing)\n",
    "        # print((index_interval, len(corr_sample_training), len(corr_sample_testing), mannwhitneyu_test[0], mannwhitneyu_test[1]))\n",
    "\n",
    "        if mannwhitneyu_test[1] <= 0.05: # positive detection\n",
    "            # if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0])\n",
    "            #        or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])\n",
    "            #            or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])):\n",
    "            if (binary_search(intervals_testing[index_interval][0], attack_metadata[attack_metadata_keys[index_attack]])) or (binary_search(intervals_testing[index_interval][1], attack_metadata[attack_metadata_keys[index_attack]])):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else: # negative detection\n",
    "            # if ((intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0])\n",
    "            #        or (intervals_testing[index_interval][0] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][0] and intervals_testing[index_interval][1] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])\n",
    "            #            or (intervals_testing[index_interval][0] < attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1] and intervals_testing[index_interval][1] > attack_metadata[attack_metadata_keys[index_attack]][\"injection_interval\"][1])):\n",
    "            if (binary_search(intervals_testing[index_interval][0], attack_metadata[attack_metadata_keys[index_attack]])) or (binary_search(intervals_testing[index_interval][1], attack_metadata[attack_metadata_keys[index_attack]])):    \n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    # precision\n",
    "    if tp + fp != 0:            \n",
    "        precision = tp/(tp + fp)\n",
    "    else:\n",
    "        precision = np.nan\n",
    "        \n",
    "    # recall\n",
    "    if tp + fn != 0:\n",
    "        recall = tp/(tp + fn)\n",
    "    else:\n",
    "        recall = np.nan\n",
    "        \n",
    "    # f1\n",
    "    if precision + recall != 0:\n",
    "        f1 = 2*((precision*recall)/(precision + recall))\n",
    "        \n",
    "    else:\n",
    "        f1 = np.nan\n",
    "        \n",
    "    # fpr\n",
    "    if fp + tn != 0:\n",
    "        fpr = fp/(fp + tn)\n",
    "    else:\n",
    "        fpr = np.nan\n",
    "\n",
    "    # fnr\n",
    "    if fn + tp != 0:\n",
    "        fnr = fn/(fn + tp)\n",
    "    else:\n",
    "        fnr = np.nan\n",
    "\n",
    "    # mcc\n",
    "    if (tp+fp == 0) or (tp+fn == 0) or (tn+fp == 0) or (tn+fn == 0):\n",
    "        mcc = (tp*tn) - (fp*fn)\n",
    "    else:\n",
    "        mcc = (tp*tn - fp*fn)/(math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "\n",
    "    print(f\"tp: {tp}, tn: {tn}, fp: {fp}, fn: {fn}\")\n",
    "    print(f\"precision: {precision:.3f}, recall: {recall:.3f}, f1: {f1:.3f}, fpr: {fpr:.3f}, fnr: {fnr:.3f}, mcc: {mcc:.3f}\")\n",
    "    print(f\"positive_intervals: {tp+fn:.3f}, negative_intervals: {tn+fp:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4a669b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "can-bus-py-38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "45b264e09b14a9213e177c21a39e9d77d1b55e54df33475b814f14646fc04131"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
